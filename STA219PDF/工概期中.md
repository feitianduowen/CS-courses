STA219 note
# 0 积分公式  
1. 
$$
\int_{a}^{b} f(x)\, g'(x)\,dx
   = \bigl[f(x)g(x)\bigr]_{a}^{b}
- \int_{a}^{b} f'(x)\, g(x)\,dx
$$

2. \[
   J_F(x,y)=
   \begin{bmatrix}
   \frac{\partial f_1}{\partial x} & \frac{\partial f_1}{\partial y}\\
   \frac{\partial f_2}{\partial x} & \frac{\partial f_2}{\partial y}
   \end{bmatrix}.
   \]

3. $d\tan x=\sec^2x$  

   $d\sec x=\sec x\tan x$  

   $d\cot x=-\csc^2x$  

   $d\csc x=-\csc x\cot x$  

   $d\sin^{-1}x=\frac{1}{\sqrt{1-x^2}}$  

   $d\cos^{-1}x=-\frac{1}{\sqrt{1-x^2}}$  

   $d\tan^{-1}x=\frac{1}{1+x^2}$  

4. Taylor series
   $$
   \frac{1}{1-x}
    = 1 + x + x^2 + \cdots + x^n + \cdots
    = \sum_{n=0}^{\infty} x^n,\qquad |x|<1.
   $$

   $$
   \frac{1}{1+x}
    = 1 - x + x^2 - \cdots + (-x)^n + \cdots
    = \sum_{n=0}^{\infty} (-1)^n x^n,\qquad |x|<1.
   $$

   $$
   e^{x}
    = 1 + x + \frac{x^{2}}{2!} + \cdots + \frac{x^{n}}{n!} + \cdots
    = \sum_{n=0}^{\infty} \frac{x^{n}}{n!},\qquad x\in\mathbb{R}.
   $$

   $$
   \sin x
    = x - \frac{x^{3}}{3!} + \frac{x^{5}}{5!} - \cdots + (-1)^n\frac{x^{2n+1}}{(2n+1)!} + \cdots
    = \sum_{n=0}^{\infty} (-1)^n \frac{x^{2n+1}}{(2n+1)!},\qquad x\in\mathbb{R}.
   $$

   $$
   \cos x
    = 1 - \frac{x^{2}}{2!} + \frac{x^{4}}{4!} - \cdots + (-1)^n\frac{x^{2n}}{(2n)!} + \cdots
    = \sum_{n=0}^{\infty} (-1)^n \frac{x^{2n}}{(2n)!},\qquad x\in\mathbb{R}.
   $$

   $$
   \ln(1+x)
    = x - \frac{x^{2}}{2} + \frac{x^{3}}{3} - \cdots + (-1)^{n-1}\frac{x^{n}}{n} + \cdots
    = \sum_{n=1}^{\infty} (-1)^{n-1}\frac{x^{n}}{n},\qquad -1<x\le 1.
   $$

   $$
   \tan^{-1}x
    = x-\frac{x^{3}}{3}+\frac{x^{5}}{5}-\cdots+(-1)^n\frac{x^{2n+1}}{2n+1}+\cdots
    = \sum_{n=0}^{\infty}(-1)^n\frac{x^{2n+1}}{2n+1},\qquad |x|\le 1.
   $$

5. 

# 1 Basic Ideas in Probability

1. **容斥原理**:
   $P(A_1\cap A_2\cap...\cap A_n)=\sum_{i=1}^{n}P(A_i)-\sum_{1\leq i<j\leq n}P(A_iA_j)+...(-1)^{n-1}P(A_1A_2...A_n)$  
2. $C_n^k=(_k^n)=\frac{n!}{k!(n-k)!}$  

# 2 Random Variables and Distribution

1. **琴生**:  
   凸: $E(g(X))\geq g(E(X))$  
   凹: $E(g(X))\leq g(E(X))$

- $E(|X|) \geq |E(X)|$ $(g(x) = |x|)$
- $E(X^2) \geq (E(X))^2$ $(g(x) = x^2)$
- $E(|X|^p) \geq |E(X)|^p$ 对于 $p \geq 1$ $(g(x) = |x|^p,  p \geq 1)$  
- $E(e^{cX}) \geq e^{cE(X)}$ $(g(x) = e^{cX})$

2. $Y=g(X)$, $h(y)=g^{-1}(y)$,  
   $\Rightarrow f_Y(y)=\left\{\begin{aligned}|h'(y)|\cdot f_X(h(y)), 在h(y)有定义处\\
   0，否则\end{aligned}\right.$  

3. | 分布                   | PDF/PMF                                                      | 期望                | 方差                  |
   | :--------------------- | ------------------------------------------------------------ | ------------------- | --------------------- |
   | 均匀 $(a, b)$          | $f(x) = \begin{cases} \frac{1}{b-a}, & \text{if } a < x < b \\ 0, & \text{otherwise} \end{cases}$ | $\frac{a+b}{2}$     | $\frac{(b-a)^2}{12}$  |
   | 正态 $(\mu, \sigma^2)$ | $f(x) = \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{(x-\mu)^2}{2\sigma^2}}$ | $\mu$               | $\sigma^2$            |
   | 指数 $(\lambda)$       | $f(x) = \begin{cases} \lambda e^{-\lambda x}, & \text{if } x \geq 0 \\ 0, & \text{otherwise} \end{cases}$ | $\frac{1}{\lambda}$ | $\frac{1}{\lambda^2}$ |
   | 几何 (p)(无记忆离散)   | $p(x)=p(1-p)^{x-1}$                                          | $\frac{1}{p}$       | $\frac{1-p}{p^2}$     |
   | 泊松($\lambda$)        | $p(x)=\frac{\lambda^x}{x!}e^{-\lambda}$                      | $\lambda$           | $\lambda$             |
   | 二项(n,p)              | $p(x)=C_n^xp^x(1-p)^{n-x}$                                   | np                  | np(1-p)               |
   | 伯努利(p)              | $p(x)=p^x(1-p)^{1-x}$                                        | p                   | p(1-p)                |

4. 标准化：$Z=\frac{X-\mu}{\sigma}$
5. $E(X)=\int_{-\infty}^{\infty}xf(x)dx$  
6. $E(Y)=E(g(X))=\int_{-\infty}^{\infty}g(x)f(x)dx$  
7. $\text{Var(X)}=E(X-E(X))^2=E(X^2)-[E(X)]^2=\int_{-\infty}^{\infty}[x-E(X)]^2f(x)dx$  

# 3 Joint Distributions

1. $\text{Cov}(X,Y)=E(XY)-E(X)E(Y)=E[(X-E(X))(Y-E(Y))]$

2. $\text{Cov}(aX,bY)=ab\text{Cov}(X,Y)$

3. $\text{Var}(X\pm Y )=\text{Var}(X)+\text{Var}(Y)\pm 2\text{Cov}(X,Y)$

4. $\text{Cov}(\sum_{i=1}^{n}a_iX_i,\sum_{j=1}^{m}b_jY_j)=\sum_{i=1}^{n}\sum_{i=1}^{m}a_ib_j\text{Cov}(X_i,Y_j)$

5. $\rho_{XY}=Cor(X,Y)=\frac{\text{Cov}(X,Y)}{\sqrt{\text{Var}(X)\text{Var}(Y)}}$

6. **MSE**:   
   $b_0=\frac{\text{Cov}(X,Y)}{\text{Var}(X)}$  
   $a_0=E(Y)-\frac{\text{Cov}(X,Y)}{\text{Var}(X)}E(X)$  
   $\min\limits_{a,b}MSE=\text{Var}(Y)(1-\rho^2_{XY})$

7. **Law of total expectation**: $E(X)=E((X|Y))$  

   $E(X)=\int_{-\infty}^\infty E(X|Y=y)\cdot f_Y(y)dy$

